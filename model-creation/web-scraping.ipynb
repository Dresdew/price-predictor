{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import logging\n",
    "from typing import List, Dict\n",
    "import aiohttp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "level = logging.INFO\n",
    "fmt = '[%(levelname)s] - %(message)s'\n",
    "logging.basicConfig(level=level, format=fmt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('features.json') as f:\n",
    "    feature_list = json.loads(f.read())\n",
    "    features = {f['key']: f for f in feature_list}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def find_ad_url_list(amount_of_page: int, district: str) -> List[str]:\n",
    "    ad_url_list = []\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        for page in range(amount_of_page):\n",
    "            url = f'https://ingatlanok.hu/elado/lakas/budapest-{district}/20Mft-tol;70Mft-ig?page={page}'\n",
    "            async with session.get(url) as resp:\n",
    "                html_text = await resp.text()\n",
    "                soup = BeautifulSoup(html_text, 'html.parser')\n",
    "                ad_url = [item['data-original-url']\n",
    "                          for item in soup.select('[data-original-url]')]\n",
    "                ad_url_list.extend(ad_url)\n",
    "                logging.info('scraping ad urls: %d / %d', page, amount_of_page)\n",
    "    return ad_url_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_feature_by_displaying_name(name):\n",
    "    return next((f for f in features.values() if f['displayingName'] == name), None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ad_data(html:str, district:str)-> Dict[str, str]:\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    tables = soup.findAll('tbody')\n",
    "    tr_elements = [*tables[0].find_all('tr'), *tables[1].find_all('tr')]\n",
    "    ad = {'DISTRICT':district}\n",
    "    for tr_element in tr_elements:\n",
    "        td_1, td_2 = tr_element.find_all('td')\n",
    "        displaying_name = td_1.text[:-1]\n",
    "        feature = find_feature_by_displaying_name(displaying_name)\n",
    "        if not feature:\n",
    "            continue\n",
    "        value = td_2.text.replace('\\n', '')\n",
    "        ad[feature[\"key\"]]=value\n",
    "    return ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_and_process_ad_list(ad_url_list:List[str], district:str) -> List[str]:\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        ad_data = []\n",
    "        for url in ad_url_list:\n",
    "            async with session.get(url) as resp:\n",
    "                html_text = await resp.text()\n",
    "                ad_data.append(process_ad_data(html_text, district))\n",
    "                if len(ad_data) % 50 ==0:\n",
    "                    logging.info('processing ad of district %d: %d / %d',district, len(ad_data), len(ad_url_list))\n",
    "        return ad_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] - scraping ad urls: 0 / 15\n",
      "[INFO] - scraping ad urls: 1 / 15\n",
      "[INFO] - scraping ad urls: 2 / 15\n",
      "[INFO] - scraping ad urls: 3 / 15\n",
      "[INFO] - scraping ad urls: 4 / 15\n",
      "[INFO] - scraping ad urls: 5 / 15\n",
      "[INFO] - scraping ad urls: 6 / 15\n",
      "[INFO] - scraping ad urls: 7 / 15\n",
      "[INFO] - scraping ad urls: 8 / 15\n",
      "[INFO] - scraping ad urls: 9 / 15\n",
      "[INFO] - scraping ad urls: 10 / 15\n",
      "[INFO] - scraping ad urls: 11 / 15\n",
      "[INFO] - scraping ad urls: 12 / 15\n",
      "[INFO] - scraping ad urls: 13 / 15\n",
      "[INFO] - scraping ad urls: 14 / 15\n",
      "[INFO] - processing ad: 10 / 97\n",
      "[INFO] - processing ad: 20 / 97\n",
      "[INFO] - processing ad: 30 / 97\n",
      "[INFO] - processing ad: 40 / 97\n",
      "[INFO] - processing ad: 50 / 97\n",
      "[INFO] - processing ad: 60 / 97\n",
      "[INFO] - processing ad: 70 / 97\n",
      "[INFO] - processing ad: 80 / 97\n",
      "[INFO] - processing ad: 90 / 97\n",
      "[INFO] - scraping ad urls: 0 / 15\n",
      "[INFO] - scraping ad urls: 1 / 15\n",
      "[INFO] - scraping ad urls: 2 / 15\n",
      "[INFO] - scraping ad urls: 3 / 15\n",
      "[INFO] - scraping ad urls: 4 / 15\n",
      "[INFO] - scraping ad urls: 5 / 15\n",
      "[INFO] - scraping ad urls: 6 / 15\n",
      "[INFO] - scraping ad urls: 7 / 15\n",
      "[INFO] - scraping ad urls: 8 / 15\n",
      "[INFO] - scraping ad urls: 9 / 15\n",
      "[INFO] - scraping ad urls: 10 / 15\n",
      "[INFO] - scraping ad urls: 11 / 15\n",
      "[INFO] - scraping ad urls: 12 / 15\n",
      "[INFO] - scraping ad urls: 13 / 15\n",
      "[INFO] - scraping ad urls: 14 / 15\n",
      "[INFO] - processing ad: 10 / 189\n",
      "[INFO] - processing ad: 20 / 189\n",
      "[INFO] - processing ad: 30 / 189\n",
      "[INFO] - processing ad: 40 / 189\n",
      "[INFO] - processing ad: 50 / 189\n",
      "[INFO] - processing ad: 60 / 189\n",
      "[INFO] - processing ad: 70 / 189\n",
      "[INFO] - processing ad: 80 / 189\n",
      "[INFO] - processing ad: 90 / 189\n",
      "[INFO] - processing ad: 100 / 189\n",
      "[INFO] - processing ad: 110 / 189\n",
      "[INFO] - processing ad: 120 / 189\n",
      "[INFO] - processing ad: 130 / 189\n",
      "[INFO] - processing ad: 140 / 189\n",
      "[INFO] - processing ad: 150 / 189\n",
      "[INFO] - processing ad: 160 / 189\n",
      "[INFO] - processing ad: 170 / 189\n",
      "[INFO] - processing ad: 180 / 189\n",
      "[INFO] - scraping ad urls: 0 / 15\n",
      "[INFO] - scraping ad urls: 1 / 15\n",
      "[INFO] - scraping ad urls: 2 / 15\n",
      "[INFO] - scraping ad urls: 3 / 15\n",
      "[INFO] - scraping ad urls: 4 / 15\n",
      "[INFO] - scraping ad urls: 5 / 15\n",
      "[INFO] - scraping ad urls: 6 / 15\n",
      "[INFO] - scraping ad urls: 7 / 15\n",
      "[INFO] - scraping ad urls: 8 / 15\n",
      "[INFO] - scraping ad urls: 9 / 15\n",
      "[INFO] - scraping ad urls: 10 / 15\n",
      "[INFO] - scraping ad urls: 11 / 15\n",
      "[INFO] - scraping ad urls: 12 / 15\n",
      "[INFO] - scraping ad urls: 13 / 15\n",
      "[INFO] - scraping ad urls: 14 / 15\n",
      "[INFO] - processing ad: 10 / 105\n",
      "[INFO] - processing ad: 20 / 105\n",
      "[INFO] - processing ad: 30 / 105\n",
      "[INFO] - processing ad: 40 / 105\n",
      "[INFO] - processing ad: 50 / 105\n",
      "[INFO] - processing ad: 60 / 105\n",
      "[INFO] - processing ad: 70 / 105\n",
      "[INFO] - processing ad: 80 / 105\n",
      "[INFO] - processing ad: 90 / 105\n",
      "[INFO] - processing ad: 100 / 105\n",
      "[INFO] - scraping ad urls: 0 / 15\n",
      "[INFO] - scraping ad urls: 1 / 15\n",
      "[INFO] - scraping ad urls: 2 / 15\n",
      "[INFO] - scraping ad urls: 3 / 15\n",
      "[INFO] - scraping ad urls: 4 / 15\n",
      "[INFO] - scraping ad urls: 5 / 15\n",
      "[INFO] - scraping ad urls: 6 / 15\n",
      "[INFO] - scraping ad urls: 7 / 15\n",
      "[INFO] - scraping ad urls: 8 / 15\n",
      "[INFO] - scraping ad urls: 9 / 15\n",
      "[INFO] - scraping ad urls: 10 / 15\n",
      "[INFO] - scraping ad urls: 11 / 15\n",
      "[INFO] - scraping ad urls: 12 / 15\n",
      "[INFO] - scraping ad urls: 13 / 15\n",
      "[INFO] - scraping ad urls: 14 / 15\n",
      "[INFO] - processing ad: 10 / 278\n",
      "[INFO] - processing ad: 20 / 278\n",
      "[INFO] - processing ad: 30 / 278\n",
      "[INFO] - processing ad: 40 / 278\n",
      "[INFO] - processing ad: 50 / 278\n",
      "[INFO] - processing ad: 60 / 278\n",
      "[INFO] - processing ad: 70 / 278\n",
      "[INFO] - processing ad: 80 / 278\n",
      "[INFO] - processing ad: 90 / 278\n",
      "[INFO] - processing ad: 100 / 278\n",
      "[INFO] - processing ad: 110 / 278\n",
      "[INFO] - processing ad: 120 / 278\n",
      "[INFO] - processing ad: 130 / 278\n",
      "[INFO] - processing ad: 140 / 278\n",
      "[INFO] - processing ad: 150 / 278\n",
      "[INFO] - processing ad: 160 / 278\n",
      "[INFO] - processing ad: 170 / 278\n",
      "[INFO] - processing ad: 180 / 278\n",
      "[INFO] - processing ad: 190 / 278\n",
      "[INFO] - processing ad: 200 / 278\n",
      "[INFO] - processing ad: 210 / 278\n",
      "[INFO] - processing ad: 220 / 278\n",
      "[INFO] - processing ad: 230 / 278\n",
      "[INFO] - processing ad: 240 / 278\n",
      "[INFO] - processing ad: 250 / 278\n",
      "[INFO] - processing ad: 260 / 278\n",
      "[INFO] - processing ad: 270 / 278\n",
      "[INFO] - scraping ad urls: 0 / 15\n",
      "[INFO] - scraping ad urls: 1 / 15\n",
      "[INFO] - scraping ad urls: 2 / 15\n",
      "[INFO] - scraping ad urls: 3 / 15\n",
      "[INFO] - scraping ad urls: 4 / 15\n",
      "[INFO] - scraping ad urls: 5 / 15\n",
      "[INFO] - scraping ad urls: 6 / 15\n",
      "[INFO] - scraping ad urls: 7 / 15\n",
      "[INFO] - scraping ad urls: 8 / 15\n",
      "[INFO] - scraping ad urls: 9 / 15\n",
      "[INFO] - scraping ad urls: 10 / 15\n",
      "[INFO] - scraping ad urls: 11 / 15\n",
      "[INFO] - scraping ad urls: 12 / 15\n",
      "[INFO] - scraping ad urls: 13 / 15\n",
      "[INFO] - scraping ad urls: 14 / 15\n",
      "[INFO] - processing ad: 10 / 300\n",
      "[INFO] - processing ad: 20 / 300\n",
      "[INFO] - processing ad: 30 / 300\n",
      "[INFO] - processing ad: 40 / 300\n",
      "[INFO] - processing ad: 50 / 300\n",
      "[INFO] - processing ad: 60 / 300\n",
      "[INFO] - processing ad: 70 / 300\n",
      "[INFO] - processing ad: 80 / 300\n",
      "[INFO] - processing ad: 90 / 300\n",
      "[INFO] - processing ad: 100 / 300\n",
      "[INFO] - processing ad: 110 / 300\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-f54e6dd550e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdistrict\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DISTRICT_NUM'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'values'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mad_url_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mfind_ad_url_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistrict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mget_and_process_ad_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mad_url_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistrict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mad_raw_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-23035c5cf3e0>\u001b[0m in \u001b[0;36mget_and_process_ad_list\u001b[0;34m(ad_url_list, district_num)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mad_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0murl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mad_url_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             \u001b[0;32masync\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m                 \u001b[0mhtml_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                 \u001b[0mad_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_ad_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistrict_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/aiohttp/client.py\u001b[0m in \u001b[0;36m__aenter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m__aenter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0m_RetType\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coro\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/aiohttp/client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, method, str_or_url, params, data, json, cookies, headers, skip_auto_headers, auth, allow_redirects, max_redirects, compress, chunked, expect100, raise_for_status, read_until_eof, proxy, proxy_auth, timeout, verify_ssl, fingerprint, ssl_context, ssl, proxy_headers, trace_request_ctx, read_bufsize)\u001b[0m\n\u001b[1;32m    542\u001b[0m                             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m                             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m                                 \u001b[0;32mawait\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    545\u001b[0m                             \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m                                 \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/aiohttp/client_reqrep.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self, connection)\u001b[0m\n\u001b[1;32m    888\u001b[0m                 \u001b[0;31m# read response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m                     \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpayload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    891\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHttpProcessingError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m                     raise ClientResponseError(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/aiohttp/streams.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_waiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_future\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m                 \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_waiter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCancelledError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_waiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCancelledError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ad_raw_data = []\n",
    "for district in features['DISTRICT']['values']:\n",
    "    ad_url_list = await find_ad_url_list(15, district)\n",
    "    data = await get_and_process_ad_list(ad_url_list, district)\n",
    "    ad_raw_data.extend(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = pd.DataFrame(ad_raw_data)\n",
    "raw_dataset.to_pickle('ad.pkl')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
