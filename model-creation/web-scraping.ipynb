{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import logging\n",
    "from typing import List, Dict\n",
    "import aiohttp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "level = logging.INFO\n",
    "fmt = '[%(levelname)s] - %(message)s'\n",
    "logging.basicConfig(level=level, format=fmt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('features.json') as f:\n",
    "    feature_list = json.loads(f.read())\n",
    "    features = {f['key']: f for f in feature_list}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def find_ad_url_list(amount_of_page: int, district: str) -> List[str]:\n",
    "    ad_url_list = []\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        for page in range(amount_of_page):\n",
    "            url = f'https://ingatlanok.hu/elado/lakas/budapest-{district}/20Mft-tol;70Mft-ig?page={page}'\n",
    "            async with session.get(url) as resp:\n",
    "                html_text = await resp.text()\n",
    "                soup = BeautifulSoup(html_text, 'html.parser')\n",
    "                ad_url = [item['data-original-url']\n",
    "                          for item in soup.select('[data-original-url]')]\n",
    "                ad_url_list.extend(ad_url)\n",
    "                logging.info('%d / %d', page, amount_of_page)\n",
    "    return ad_url_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_feature_by_displaying_name(name):\n",
    "    return next((f for f in features.values() if f['displayingName'] == name), None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ad_data(html:str, district_name:str)-> Dict[str, str]:\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    tables = soup.findAll('tbody')\n",
    "    tr_elements = [*tables[0].find_all('tr'), *tables[1].find_all('tr')]\n",
    "    ad = {'DISTRICT_NUM':district_name}\n",
    "    for tr_element in tr_elements:\n",
    "        td_1, td_2 = tr_element.find_all('td')\n",
    "        displaying_name = td_1.text[:-1]\n",
    "        feature = find_feature_by_displaying_name(displaying_name)\n",
    "        if not feature:\n",
    "            continue\n",
    "        value = td_2.text.replace('\\n', '')\n",
    "        ad[feature[\"key\"]]=value\n",
    "    return ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch_and_process_ad_list(ad_url_list:List[str], district_num:int) -> List[str]:\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        ad_data = []\n",
    "        for url in ad_url_list:\n",
    "            async with session.get(url) as resp:\n",
    "                html_text = await resp.text()\n",
    "                ad_data.append(process_ad_data(html_text, district_num))\n",
    "                if len(ad_data) % 10 ==0:\n",
    "                    logging.info('%d / %d', len(ad_data), len(ad_url_list))\n",
    "        return ad_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] - 0 / 1\n",
      "[INFO] - 10 / 20\n",
      "[INFO] - 20 / 20\n",
      "[INFO] - 0 / 1\n",
      "[INFO] - 10 / 20\n",
      "[INFO] - 20 / 20\n",
      "[INFO] - 0 / 1\n",
      "[INFO] - 10 / 20\n",
      "[INFO] - 20 / 20\n",
      "[INFO] - 0 / 1\n",
      "[INFO] - 10 / 20\n",
      "[INFO] - 20 / 20\n",
      "[INFO] - 0 / 1\n",
      "[INFO] - 10 / 20\n",
      "[INFO] - 20 / 20\n",
      "[INFO] - 0 / 1\n",
      "[INFO] - 10 / 20\n",
      "[INFO] - 20 / 20\n"
     ]
    }
   ],
   "source": [
    "ad_raw_data = []\n",
    "for district in features['DISTRICT_NUM']['values']:\n",
    "    ad_url_list = await find_ad_url_list(1, district)\n",
    "    data = await fetch_and_process_ad_list(ad_url_list, district)\n",
    "    ad_raw_data.extend(data)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
